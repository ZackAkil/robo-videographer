{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_FOLDER_PATH = \"/Users/zackakil/Desktop/capture clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_labels = pd.Series.from_csv('rugby_image_labels.csv')\n",
    "image_labels = image_labels.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1489359202.14.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels.keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = {}\n",
    "\n",
    "face = misc.imread(IMAGE_FOLDER_PATH+image_labels.keys()[0], flatten=True)\n",
    "face1 = misc.imread(IMAGE_FOLDER_PATH+image_labels.keys()[1], flatten=True)     \n",
    "plt.imshow((face[200:300] - face1[200:300])>30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UPPER_FRAME = 300\n",
    "LOWER_FRAME = 200\n",
    "THRESHOLD = 30\n",
    "def comapare_frames(frame_1_file_name, frame_2_file_name):\n",
    "    f1 = misc.imread(frame_1_file_name, flatten=True)\n",
    "    f2 = misc.imread(frame_2_file_name, flatten=True)\n",
    "    diff = (f1[LOWER_FRAME:UPPER_FRAME] - f2[LOWER_FRAME:UPPER_FRAME])>THRESHOLD\n",
    "    return [diff.sum(axis=0),diff]\n",
    "\n",
    "def get_image(file_name):\n",
    "    return misc.imread(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_images(image_labels, image_folder_name):\n",
    "    '''\n",
    "    Create lists of engneered image features.\n",
    "    '''\n",
    "\n",
    "    frame_compares_sum = []\n",
    "    frame_compares = []\n",
    "    frame_images = []\n",
    "    i = 0\n",
    "    images_to_process = image_labels[:]\n",
    "    for index, value in images_to_process[:-1].iteritems():\n",
    "        i += 1\n",
    "        curr_image = image_folder_name + index\n",
    "        next_image_index = image_labels.index.get_loc(index)+1\n",
    "        next_image_key = image_folder_name + image_labels.keys()[next_image_index]\n",
    "        out = comapare_frames(curr_image, next_image_key)\n",
    "        frame_compares.append(out[1])\n",
    "        frame_compares_sum.append(out[0])\n",
    "        frame_images.append(get_image(next_image_key))\n",
    "        if not (i % 25):\n",
    "            print('{0} images processed'.format(i))\n",
    "    return (frame_compares_sum, frame_compares, frame_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 images processed\n",
      "50 images processed\n",
      "75 images processed\n",
      "100 images processed\n",
      "125 images processed\n",
      "150 images processed\n",
      "175 images processed\n",
      "200 images processed\n",
      "225 images processed\n",
      "250 images processed\n",
      "275 images processed\n",
      "300 images processed\n",
      "325 images processed\n",
      "350 images processed\n",
      "375 images processed\n",
      "400 images processed\n",
      "425 images processed\n",
      "450 images processed\n",
      "475 images processed\n",
      "500 images processed\n",
      "525 images processed\n",
      "550 images processed\n",
      "575 images processed\n",
      "600 images processed\n",
      "625 images processed\n",
      "650 images processed\n",
      "675 images processed\n",
      "700 images processed\n",
      "725 images processed\n",
      "750 images processed\n",
      "775 images processed\n",
      "800 images processed\n",
      "825 images processed\n",
      "850 images processed\n",
      "875 images processed\n",
      "900 images processed\n",
      "925 images processed\n",
      "950 images processed\n",
      "975 images processed\n",
      "1000 images processed\n",
      "1025 images processed\n",
      "1050 images processed\n",
      "1075 images processed\n",
      "1100 images processed\n",
      "1125 images processed\n",
      "1150 images processed\n",
      "1175 images processed\n",
      "1200 images processed\n",
      "1225 images processed\n",
      "1250 images processed\n",
      "1275 images processed\n",
      "1300 images processed\n",
      "1325 images processed\n",
      "1350 images processed\n",
      "1375 images processed\n",
      "1400 images processed\n",
      "1425 images processed\n",
      "1450 images processed\n",
      "1475 images processed\n",
      "1500 images processed\n",
      "1525 images processed\n",
      "1550 images processed\n",
      "1575 images processed\n",
      "1600 images processed\n",
      "1625 images processed\n",
      "1650 images processed\n",
      "1675 images processed\n",
      "1700 images processed\n",
      "1725 images processed\n",
      "1750 images processed\n",
      "1775 images processed\n",
      "1800 images processed\n",
      "1825 images processed\n",
      "1850 images processed\n",
      "1875 images processed\n",
      "1900 images processed\n",
      "1925 images processed\n",
      "1950 images processed\n",
      "1975 images processed\n",
      "2000 images processed\n",
      "2025 images processed\n",
      "2050 images processed\n",
      "2075 images processed\n",
      "2100 images processed\n",
      "2125 images processed\n",
      "2150 images processed\n",
      "2175 images processed\n",
      "2200 images processed\n",
      "2225 images processed\n",
      "2250 images processed\n",
      "2275 images processed\n",
      "2300 images processed\n",
      "2325 images processed\n",
      "2350 images processed\n",
      "2375 images processed\n",
      "2400 images processed\n",
      "2425 images processed\n",
      "2450 images processed\n",
      "2475 images processed\n",
      "2500 images processed\n",
      "2525 images processed\n"
     ]
    }
   ],
   "source": [
    "frame_compares_sum, frame_compares, frame_images = process_images(image_labels, IMAGE_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-a67ad8358574>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-a67ad8358574>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    return (**process_images(_image_labels, image_folder_name), _image_labels)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def process_images_from_folder(label_file_name, image_folder_name):\n",
    "\n",
    "    _image_labels = pd.Series.from_csv(label_file_name)\n",
    "    _image_labels = _image_labels.dropna()\n",
    "    \n",
    "    return process_images(_image_labels, image_folder_name)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_labels_2 = pd.Series.from_csv('rugby_image_labels_2.csv')\n",
    "image_labels_2 = image_labels_2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 images processed\n",
      "50 images processed\n",
      "75 images processed\n",
      "100 images processed\n",
      "125 images processed\n",
      "150 images processed\n",
      "175 images processed\n",
      "200 images processed\n",
      "225 images processed\n",
      "250 images processed\n",
      "275 images processed\n",
      "300 images processed\n",
      "325 images processed\n",
      "350 images processed\n",
      "375 images processed\n",
      "400 images processed\n",
      "425 images processed\n",
      "450 images processed\n",
      "475 images processed\n",
      "500 images processed\n",
      "525 images processed\n",
      "550 images processed\n",
      "575 images processed\n",
      "600 images processed\n",
      "625 images processed\n",
      "650 images processed\n",
      "675 images processed\n",
      "700 images processed\n",
      "725 images processed\n",
      "750 images processed\n",
      "775 images processed\n",
      "800 images processed\n",
      "825 images processed\n",
      "850 images processed\n",
      "875 images processed\n",
      "900 images processed\n",
      "925 images processed\n",
      "950 images processed\n",
      "975 images processed\n",
      "1000 images processed\n",
      "1025 images processed\n",
      "1050 images processed\n",
      "1075 images processed\n",
      "1100 images processed\n",
      "1125 images processed\n",
      "1150 images processed\n",
      "1175 images processed\n",
      "1200 images processed\n",
      "1225 images processed\n",
      "1250 images processed\n",
      "1275 images processed\n",
      "1300 images processed\n",
      "1325 images processed\n",
      "1350 images processed\n",
      "1375 images processed\n",
      "1400 images processed\n",
      "1425 images processed\n",
      "1450 images processed\n",
      "1475 images processed\n",
      "1500 images processed\n",
      "1525 images processed\n",
      "1550 images processed\n",
      "1575 images processed\n",
      "1600 images processed\n",
      "1625 images processed\n",
      "1650 images processed\n",
      "1675 images processed\n",
      "1700 images processed\n",
      "1725 images processed\n",
      "1750 images processed\n",
      "1775 images processed\n",
      "1800 images processed\n",
      "1825 images processed\n",
      "1850 images processed\n",
      "1875 images processed\n",
      "1900 images processed\n",
      "1925 images processed\n",
      "1950 images processed\n",
      "1975 images processed\n",
      "2000 images processed\n",
      "2025 images processed\n",
      "2050 images processed\n",
      "2075 images processed\n",
      "2100 images processed\n",
      "2125 images processed\n",
      "2150 images processed\n",
      "2175 images processed\n",
      "2200 images processed\n",
      "2225 images processed\n",
      "2250 images processed\n",
      "2275 images processed\n",
      "2300 images processed\n",
      "2325 images processed\n",
      "2350 images processed\n",
      "2375 images processed\n",
      "2400 images processed\n",
      "2425 images processed\n",
      "2450 images processed\n",
      "2475 images processed\n",
      "2500 images processed\n",
      "2525 images processed\n",
      "2550 images processed\n",
      "2575 images processed\n",
      "2600 images processed\n",
      "2625 images processed\n",
      "2650 images processed\n",
      "2675 images processed\n",
      "2700 images processed\n",
      "2725 images processed\n",
      "2750 images processed\n",
      "2775 images processed\n",
      "2800 images processed\n",
      "2825 images processed\n"
     ]
    }
   ],
   "source": [
    "folder = \"/Users/zackakil/Desktop/capture/\"\n",
    "label_fname = 'rugby_image_labels_2.csv'\n",
    "frame_compares_sum_2, frame_compares_2, frame_images_2, images_labels_2 = process_images_from_folder(label_fname, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def temporal_data(data, frames, end_to_end=True):\n",
    "    '''\n",
    "    Join frames of sequencial items of data together into idenvidual items.\n",
    "    '''\n",
    "    output = []\n",
    "    \n",
    "    # check if user wants frames to overlap or be end-to-end     \n",
    "    if end_to_end:\n",
    "        item_end_frames = frames\n",
    "        len_adjust = 0\n",
    "    else:\n",
    "        item_end_frames = 1\n",
    "        len_adjust = frames - 1\n",
    "\n",
    "    for i in range(0, len(data) - len_adjust, item_end_frames):\n",
    "        start_array = np.array([])\n",
    "        for j in range(frames):\n",
    "            start_array = np.concatenate((start_array, data[i+j]), axis=0)\n",
    "        output.append(start_array)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4],\n",
       " [1, 2, 3, 4, 5],\n",
       " [2, 3, 4, 5, 6],\n",
       " [3, 4, 5, 6, 7],\n",
       " [4, 5, 6, 7, 8],\n",
       " [5, 6, 7, 8, 9],\n",
       " [6, 7, 8, 9, 10],\n",
       " [7, 8, 9, 10, 11],\n",
       " [8, 9, 10, 11, 12],\n",
       " [9, 10, 11, 12, 13],\n",
       " [10, 11, 12, 13, 14],\n",
       " [11, 12, 13, 14, 15],\n",
       " [12, 13, 14, 15, 16],\n",
       " [13, 14, 15, 16, 17],\n",
       " [14, 15, 16, 17, 18],\n",
       " [15, 16, 17, 18, 19],\n",
       " [16, 17, 18, 19, 20],\n",
       " [17, 18, 19, 20, 21],\n",
       " [18, 19, 20, 21, 22],\n",
       " [19, 20, 21, 22, 23]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tet = []\n",
    "for i in range(20):\n",
    "    tet.append(list(range(i, i+5)))\n",
    "tet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.,  1.,  2.,  3.,  4.,  1.,  2.,  3.,  4.,  5.]),\n",
       " array([ 1.,  2.,  3.,  4.,  5.,  2.,  3.,  4.,  5.,  6.]),\n",
       " array([ 2.,  3.,  4.,  5.,  6.,  3.,  4.,  5.,  6.,  7.]),\n",
       " array([ 3.,  4.,  5.,  6.,  7.,  4.,  5.,  6.,  7.,  8.]),\n",
       " array([ 4.,  5.,  6.,  7.,  8.,  5.,  6.,  7.,  8.,  9.]),\n",
       " array([  5.,   6.,   7.,   8.,   9.,   6.,   7.,   8.,   9.,  10.]),\n",
       " array([  6.,   7.,   8.,   9.,  10.,   7.,   8.,   9.,  10.,  11.]),\n",
       " array([  7.,   8.,   9.,  10.,  11.,   8.,   9.,  10.,  11.,  12.]),\n",
       " array([  8.,   9.,  10.,  11.,  12.,   9.,  10.,  11.,  12.,  13.]),\n",
       " array([  9.,  10.,  11.,  12.,  13.,  10.,  11.,  12.,  13.,  14.]),\n",
       " array([ 10.,  11.,  12.,  13.,  14.,  11.,  12.,  13.,  14.,  15.]),\n",
       " array([ 11.,  12.,  13.,  14.,  15.,  12.,  13.,  14.,  15.,  16.]),\n",
       " array([ 12.,  13.,  14.,  15.,  16.,  13.,  14.,  15.,  16.,  17.]),\n",
       " array([ 13.,  14.,  15.,  16.,  17.,  14.,  15.,  16.,  17.,  18.]),\n",
       " array([ 14.,  15.,  16.,  17.,  18.,  15.,  16.,  17.,  18.,  19.]),\n",
       " array([ 15.,  16.,  17.,  18.,  19.,  16.,  17.,  18.,  19.,  20.]),\n",
       " array([ 16.,  17.,  18.,  19.,  20.,  17.,  18.,  19.,  20.,  21.]),\n",
       " array([ 17.,  18.,  19.,  20.,  21.,  18.,  19.,  20.,  21.,  22.]),\n",
       " array([ 18.,  19.,  20.,  21.,  22.,  19.,  20.,  21.,  22.,  23.])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_data(tet, 2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_sum(data_array, bins):\n",
    "    bin_size = int(len(data_array)/bins)\n",
    "    return data_array.reshape(-1, bin_size).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 32, 44, 65, 70,  5, 21, 10,  0,  0,  8,  3,  9,  0,  0,  0,  0,\n",
       "        0,  1,  0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_sum(frame_compares_sum[0],20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animated visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1)\n",
    "\n",
    "im = ax1.imshow(frame_images_2[0][LOWER_FRAME:UPPER_FRAME], animated=True)\n",
    "im2 = ax2.imshow(frame_compares_2[0], animated=True)\n",
    "to_plot = frame_compares_sum_2[10].reshape(-1, 10).sum(axis=1)\n",
    "im3, = ax3.plot(to_plot)\n",
    "\n",
    "line = [im, im2, im3]\n",
    "\n",
    "def updatefig(i):\n",
    "    line[0].set_array(frame_images_2[i][LOWER_FRAME:UPPER_FRAME])\n",
    "    line[1].set_array(frame_compares_2[i])\n",
    "    to_plot = frame_compares_sum_2[i].reshape(-1, 10).sum(axis=1)\n",
    "    line[2].set_ydata(to_plot)   \n",
    "    return line\n",
    "\n",
    "ani = animation.FuncAnimation(fig, \n",
    "                              updatefig,\n",
    "                              np.arange(200, 300),\n",
    "                              interval=150,\n",
    "                              blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ani.save('animation.gif', writer='imagemagick', fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 18, 25, 28, 50, 22, 52, 27,  5, 21,  0, 10,  0,  0,  0,  0,  0,\n",
       "        8,  3,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_compares_sum[0].reshape(-1, 20).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.11,  0.32,  0.44,  0.65,  0.7 ,  0.05,  0.21,  0.1 ,  0.  ,\n",
       "         0.  ,  0.08,  0.03,  0.09,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.01,  0.  ]),\n",
       " array([ 0.  ,  0.55,  0.22,  0.85,  2.36,  1.75,  0.  ,  0.71,  0.01,\n",
       "         0.  ,  0.12,  2.49,  2.35,  1.48,  0.3 ,  0.34,  0.  ,  0.01,\n",
       "         0.  ,  0.  ])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bin_sum_and_normalise(sum_data, num_of_bins = 20, normalise_var = 100):\n",
    "    _binned_pixel_diffs = [bin_sum(d, num_of_bins)/normalise_var for d in sum_data]\n",
    "    return _binned_pixel_diffs\n",
    "\n",
    "binned_pixel_diffs = bin_sum_and_normalise(frame_compares_sum)\n",
    "binned_pixel_diffs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.11,  0.32,  0.44,  0.65,  0.7 ,  0.05,  0.21,  0.1 ,  0.  ,\n",
       "          0.  ,  0.08,  0.03,  0.09,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.01,  0.  ,  0.  ,  0.55,  0.22,  0.85,  2.36,  1.75,  0.  ,\n",
       "          0.71,  0.01,  0.  ,  0.12,  2.49,  2.35,  1.48,  0.3 ,  0.34,\n",
       "          0.  ,  0.01,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.55,  0.22,  0.85,  2.36,  1.75,  0.  ,  0.71,  0.01,\n",
       "          0.  ,  0.12,  2.49,  2.35,  1.48,  0.3 ,  0.34,  0.  ,  0.01,\n",
       "          0.  ,  0.  ,  0.  ,  0.2 ,  0.16,  0.22,  0.59,  0.35,  0.  ,\n",
       "          0.  ,  0.  ,  0.  ,  0.09,  0.03,  0.02,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temporal bundel multiple frames together into rows\n",
    "num_of_frames_per_row = 2\n",
    "temporaly_bundeled_data =  np.matrix(temporal_data(binned_pixel_diffs, num_of_frames_per_row, end_to_end=False))\n",
    "temporaly_bundeled_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.221875 ,  0.2484375,  0.24375  ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather desired output to match with last frame of bundeled data\n",
    "# normilsie by the maximum pixel location (640 becuassee that is the width of the frame)\n",
    "normalise_var = 640\n",
    "desired_output_for_frames = image_labels.values[1:-1]/normalise_var\n",
    "desired_output_for_frames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.221875 ,  0.2484375,  0.24375  ]),\n",
       " matrix([[ 0.11,  0.32,  0.44,  0.65,  0.7 ,  0.05,  0.21,  0.1 ,  0.  ,\n",
       "           0.  ,  0.08,  0.03,  0.09,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "           0.01,  0.  ,  0.  ,  0.55,  0.22,  0.85,  2.36,  1.75,  0.  ,\n",
       "           0.71,  0.01,  0.  ,  0.12,  2.49,  2.35,  1.48,  0.3 ,  0.34,\n",
       "           0.  ,  0.01,  0.  ,  0.  ],\n",
       "         [ 0.  ,  0.55,  0.22,  0.85,  2.36,  1.75,  0.  ,  0.71,  0.01,\n",
       "           0.  ,  0.12,  2.49,  2.35,  1.48,  0.3 ,  0.34,  0.  ,  0.01,\n",
       "           0.  ,  0.  ,  0.  ,  0.2 ,  0.16,  0.22,  0.59,  0.35,  0.  ,\n",
       "           0.  ,  0.  ,  0.  ,  0.09,  0.03,  0.02,  0.  ,  0.  ,  0.  ,\n",
       "           0.  ,  0.  ,  0.  ,  0.  ],\n",
       "         [ 0.  ,  0.2 ,  0.16,  0.22,  0.59,  0.35,  0.  ,  0.  ,  0.  ,\n",
       "           0.  ,  0.09,  0.03,  0.02,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "           0.  ,  0.  ,  0.  ,  0.01,  0.15,  0.61,  0.56,  0.29,  0.  ,\n",
       "           0.  ,  0.  ,  0.  ,  0.08,  0.11,  0.06,  0.  ,  0.  ,  0.  ,\n",
       "           0.  ,  0.03,  0.  ,  0.  ],\n",
       "         [ 0.  ,  0.01,  0.15,  0.61,  0.56,  0.29,  0.  ,  0.  ,  0.  ,\n",
       "           0.  ,  0.08,  0.11,  0.06,  0.  ,  0.  ,  0.  ,  0.  ,  0.03,\n",
       "           0.  ,  0.  ,  0.  ,  0.  ,  0.83,  0.22,  0.3 ,  0.45,  0.  ,\n",
       "           0.03,  0.  ,  0.  ,  0.11,  0.24,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "           0.  ,  0.01,  0.  ,  0.  ]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bundle_and_normalise(sum_data, image_labels, num_of_frames_per_row=2, normalise_var=640): \n",
    "    temporaly_bundeled_data =  np.matrix(temporal_data(sum_data, num_of_frames_per_row, end_to_end=False))\n",
    "    desired_output_for_frames = image_labels.values[1:-1]/normalise_var\n",
    "    return (temporaly_bundeled_data, desired_output_for_frames)\n",
    "\n",
    "temporaly_bundeled_data, desired_output_for_frames = bundle_and_normalise(binned_pixel_diffs, image_labels)\n",
    "\n",
    "desired_output_for_frames[:3], temporaly_bundeled_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2532, 2532)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(desired_output_for_frames), len(temporaly_bundeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transofrm_data_into_input_data_format(pixel_sum_data, image_labels):\n",
    "    _binned_pixel_diffs = bin_sum_and_normalise(pixel_sum_data)\n",
    "    return bundle_and_normalise(_binned_pixel_diffs, image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i_1, o_1 = transofrm_data_into_input_data_format(frame_compares_sum, image_labels)\n",
    "i_2, o_2 = transofrm_data_into_input_data_format(frame_compares_sum_2, image_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5358, 40)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs = np.concatenate((i_1, i_2))\n",
    "all_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5358,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs = np.concatenate((o_1, o_2))\n",
    "all_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# mnist = fetch_mldata(\"MNIST original\")\n",
    "# rescale the data, use the traditional train/test split\n",
    "# X, y = temporaly_bundeled_data, desired_output_for_frames\n",
    "X, y = all_inputs, all_outputs\n",
    "split_boundary = 2000\n",
    "X_train, X_test = X[:split_boundary], X[split_boundary:]\n",
    "y_train, y_test = y[:split_boundary], y[split_boundary:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "                        X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.723692\n",
      "Test set score: 0.614937\n",
      "0.9\n",
      "Training set score: 0.768655\n",
      "Test set score: 0.710480\n",
      "0.8\n",
      "Training set score: 0.781157\n",
      "Test set score: 0.748301\n",
      "0.7\n",
      "Training set score: 0.798824\n",
      "Test set score: 0.754357\n",
      "0.6\n",
      "Training set score: 0.808120\n",
      "Test set score: 0.769145\n",
      "0.5\n",
      "Training set score: 0.812376\n",
      "Test set score: 0.771438\n",
      "0.4\n",
      "Training set score: 0.813952\n",
      "Test set score: 0.778593\n",
      "0.30000000000000004\n",
      "Training set score: 0.813058\n",
      "Test set score: 0.790092\n",
      "0.19999999999999996\n",
      "Training set score: 0.823484\n",
      "Test set score: 0.789914\n",
      "0.09999999999999998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "layer_vals = list(range(1,10,1))\n",
    "for i in layer_vals:\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "                        X, y, test_size=1 - (i/10), random_state=42)\n",
    "    rgr = MLPRegressor(hidden_layer_sizes=(25), max_iter=2000, alpha=15,\n",
    "                        solver='lbfgs', verbose=10, tol=1e-4, random_state=1,\n",
    "                        learning_rate_init=.1)\n",
    "\n",
    "    rgr.fit(X_train_t, y_train_t)\n",
    "    train_score = rgr.score(X_train_t, y_train_t)\n",
    "    test_score = rgr.score(X_test_t, y_test_t)\n",
    "    print(\"Training set score: %f\" % train_score)\n",
    "    print(\"Test set score: %f\" % test_score)\n",
    "    train_results.append(train_score)\n",
    "    test_results.append(test_score)\n",
    "    print(1 - (i/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_results, c ='g')\n",
    "plt.plot(test_results, c ='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4286, 20)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t[:,:20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.813058\n",
      "Test set score: 0.790092\n"
     ]
    }
   ],
   "source": [
    "rgr = MLPRegressor(hidden_layer_sizes=(25), max_iter=2000, alpha=15,\n",
    "                    solver='lbfgs', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "rgr.fit(X_train_t, y_train_t)\n",
    "train_score = rgr.score(X_train_t, y_train_t)\n",
    "test_score = rgr.score(X_test_t, y_test_t)\n",
    "print(\"Training set score: %f\" % train_score)\n",
    "print(\"Test set score: %f\" % test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11b044cc0>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(layer_vals,train_results)\n",
    "plt.plot(layer_vals,test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x199fe5f28>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = rgr.predict(all_inputs[:1000])\n",
    "plt.plot(o, c='r')\n",
    "plt.plot(all_outputs[:1000], c='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rugby_tracker/rugby_predictor.pkl']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rgr, 'rugby_tracker/rugby_predictor.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.11,  0.32,  0.44,  0.65,  0.7 ,  0.05,  0.21,  0.1 ,  0.  ,\n",
       "          0.  ,  0.08,  0.03,  0.09,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.01,  0.  ,  0.  ,  0.55,  0.22,  0.85,  2.36,  1.75,  0.  ,\n",
       "          0.71,  0.01,  0.  ,  0.12,  2.49,  2.35,  1.48,  0.3 ,  0.34,\n",
       "          0.  ,  0.01,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.55,  0.22,  0.85,  2.36,  1.75,  0.  ,  0.71,  0.01,\n",
       "          0.  ,  0.12,  2.49,  2.35,  1.48,  0.3 ,  0.34,  0.  ,  0.01,\n",
       "          0.  ,  0.  ,  0.  ,  0.2 ,  0.16,  0.22,  0.59,  0.35,  0.  ,\n",
       "          0.  ,  0.  ,  0.  ,  0.09,  0.03,  0.02,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.2 ,  0.16,  0.22,  0.59,  0.35,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.09,  0.03,  0.02,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.  ,  0.  ,  0.01,  0.15,  0.61,  0.56,  0.29,  0.  ,\n",
       "          0.  ,  0.  ,  0.  ,  0.08,  0.11,  0.06,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.03,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.01,  0.15,  0.61,  0.56,  0.29,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.08,  0.11,  0.06,  0.  ,  0.  ,  0.  ,  0.  ,  0.03,\n",
       "          0.  ,  0.  ,  0.  ,  0.  ,  0.83,  0.22,  0.3 ,  0.45,  0.  ,\n",
       "          0.03,  0.  ,  0.  ,  0.11,  0.24,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.01,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.83,  0.22,  0.3 ,  0.45,  0.  ,  0.03,  0.  ,\n",
       "          0.  ,  0.11,  0.24,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.01,\n",
       "          0.  ,  0.  ,  0.  ,  0.09,  0.63,  0.55,  0.7 ,  0.58,  0.  ,\n",
       "          0.1 ,  0.  ,  0.  ,  0.05,  0.03,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.09,  0.63,  0.55,  0.7 ,  0.58,  0.  ,  0.1 ,  0.  ,\n",
       "          0.  ,  0.05,  0.03,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.  ,  0.  ,  0.23,  0.87,  0.83,  0.75,  0.41,  0.19,\n",
       "          0.05,  0.  ,  0.  ,  0.1 ,  0.06,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.  ,  0.05,  0.  ],\n",
       "        [ 0.  ,  0.23,  0.87,  0.83,  0.75,  0.41,  0.19,  0.05,  0.  ,\n",
       "          0.  ,  0.1 ,  0.06,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.05,  0.  ,  0.  ,  1.16,  1.08,  0.53,  0.67,  0.07,  0.24,\n",
       "          0.05,  0.  ,  0.  ,  0.19,  0.06,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  1.16,  1.08,  0.53,  0.67,  0.07,  0.24,  0.05,  0.  ,\n",
       "          0.  ,  0.19,  0.06,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.  ,  0.26,  0.13,  1.21,  0.47,  0.73,  0.1 ,  0.17,\n",
       "          0.13,  0.  ,  0.  ,  0.11,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.02,  0.  ,  0.  ],\n",
       "        [ 0.26,  0.13,  1.21,  0.47,  0.73,  0.1 ,  0.17,  0.13,  0.  ,\n",
       "          0.  ,  0.11,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.02,\n",
       "          0.  ,  0.  ,  0.25,  0.41,  1.19,  0.87,  0.76,  0.31,  0.16,\n",
       "          0.13,  0.  ,  0.  ,  0.37,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.02,  0.06,  0.  ],\n",
       "        [ 0.25,  0.41,  1.19,  0.87,  0.76,  0.31,  0.16,  0.13,  0.  ,\n",
       "          0.  ,  0.37,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.02,\n",
       "          0.06,  0.  ,  0.58,  0.87,  0.97,  1.14,  0.61,  0.14,  0.16,\n",
       "          0.15,  0.  ,  0.03,  0.15,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.05,  0.1 ,  0.  ],\n",
       "        [ 0.58,  0.87,  0.97,  1.14,  0.61,  0.14,  0.16,  0.15,  0.  ,\n",
       "          0.03,  0.15,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.05,\n",
       "          0.1 ,  0.  ,  0.24,  0.53,  1.33,  1.28,  0.54,  0.28,  0.  ,\n",
       "          0.05,  0.  ,  0.01,  0.08,  0.09,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.13,  0.01,  0.  ],\n",
       "        [ 0.24,  0.53,  1.33,  1.28,  0.54,  0.28,  0.  ,  0.05,  0.  ,\n",
       "          0.01,  0.08,  0.09,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.13,\n",
       "          0.01,  0.  ,  0.29,  0.95,  1.51,  0.37,  0.21,  0.33,  0.09,\n",
       "          0.05,  0.  ,  0.11,  0.  ,  0.15,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.  ,  0.05,  0.  ],\n",
       "        [ 0.29,  0.95,  1.51,  0.37,  0.21,  0.33,  0.09,  0.05,  0.  ,\n",
       "          0.11,  0.  ,  0.15,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.05,  0.  ,  0.74,  1.02,  1.01,  0.31,  0.18,  0.3 ,  0.03,\n",
       "          0.05,  0.  ,  0.24,  0.05,  0.06,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.12,  0.  ,  0.  ],\n",
       "        [ 0.74,  1.02,  1.01,  0.31,  0.18,  0.3 ,  0.03,  0.05,  0.  ,\n",
       "          0.24,  0.05,  0.06,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.12,\n",
       "          0.  ,  0.  ,  0.01,  0.17,  1.02,  0.32,  0.2 ,  0.16,  0.05,\n",
       "          0.06,  0.  ,  0.2 ,  0.25,  0.01,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.13,  0.09,  0.  ],\n",
       "        [ 0.01,  0.17,  1.02,  0.32,  0.2 ,  0.16,  0.05,  0.06,  0.  ,\n",
       "          0.2 ,  0.25,  0.01,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.13,\n",
       "          0.09,  0.  ,  0.13,  0.23,  0.32,  0.53,  0.17,  0.1 ,  0.  ,\n",
       "          0.11,  0.  ,  0.34,  0.34,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "          0.  ,  0.06,  0.15,  0.  ]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
